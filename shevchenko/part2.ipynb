{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2 часть дз\n",
    "Обучение моделей"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сначала нам нужно подключиться к базе данных и извлечь данные для анализа. Это можно сделать с помощью библиотеки psycopg2 и pandas."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "это для сохранения датасета в txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Данные из таблицы сохранены в файл table_data.txt\n",
      "Данные из таблицы сохранены в файл table_data.csv\n"
     ]
    }
   ],
   "source": [
    "import psycopg2\n",
    "import csv\n",
    "\n",
    "def save_table_data_to_txt():\n",
    "    conn = psycopg2.connect(\n",
    "        dbname='oirs_dz3', \n",
    "        user='kirillshevchenko', \n",
    "        password='root', \n",
    "        host='localhost'\n",
    "    )\n",
    "    cur = conn.cursor()\n",
    "\n",
    "    # Выполнение запроса SELECT для получения данных из таблицы\n",
    "    cur.execute('SELECT * FROM vk_posts')\n",
    "    table_data = cur.fetchall()\n",
    "\n",
    "    # Закрытие соединения с базой данных\n",
    "    cur.close()\n",
    "    conn.close()\n",
    "\n",
    "    # Запись данных в файл .txt\n",
    "    with open('table_data.txt', 'w') as file:\n",
    "        for row in table_data:\n",
    "            file.write(','.join(str(cell) for cell in row) + '\\n')\n",
    "\n",
    "    print(\"Данные из таблицы сохранены в файл table_data.txt\")\n",
    "\n",
    "# Вызов функции для сохранения данных из таблицы в файл\n",
    "save_table_data_to_txt()\n",
    "\n",
    "def save_table_data_to_csv():\n",
    "    conn = psycopg2.connect(\n",
    "        dbname='oirs_dz3',\n",
    "        user='kirillshevchenko',\n",
    "        password='root',\n",
    "        host='localhost'\n",
    "    )\n",
    "    cur = conn.cursor()\n",
    "\n",
    "    # Выполнение запроса SELECT для получения данных из таблицы\n",
    "    cur.execute('SELECT * FROM vk_posts')\n",
    "    table_data = cur.fetchall()\n",
    "\n",
    "    # Заголовки столбцов для CSV-файла\n",
    "    headers = ['post_id', 'text', 'likes', 'reposts', 'views']\n",
    "\n",
    "    # Закрытие соединения с базой данных\n",
    "    cur.close()\n",
    "    conn.close()\n",
    "\n",
    "    # Запись данных в файл CSV\n",
    "    with open('table_data.csv', 'w', encoding='utf-8', newline='') as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow(headers)  # Запись заголовков столбцов\n",
    "        writer.writerows(table_data)  # Запись данных\n",
    "\n",
    "    print(\"Данные из таблицы сохранены в файл table_data.csv\")\n",
    "\n",
    "# Вызов функции для сохранения данных из таблицы в файл CSV\n",
    "save_table_data_to_csv()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "import string\n",
    "from pymystem3 import Mystem\n",
    "import psycopg2\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Собираем текст.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "выбираем все посты из бд"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('/Users/kirillshevchenko/Desktop/8сем/оирс/3 дз/hw3/table_data.csv')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "обрабатываем текст"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = [\"и\", \"в\", \"во\", \"не\", \"что\", \"он\", \"на\", \"я\", \"с\", \"со\", \"как\", \"а\", \"то\", \"все\", \"она\", \"так\", \"его\", \"но\", \"да\", \"ты\", \"к\", \"у\", \"же\", \"вы\", \"за\", \"бы\", \"по\", \"только\", \"ее\", \"мне\", \"было\", \"вот\", \"от\", \"меня\", \"еще\", \"нет\", \"о\", \"из\", \"ему\", \"теперь\", \"когда\", \"даже\", \"ну\", \"вдруг\", \"ли\", \"если\", \"уже\", \"или\", \"ни\", \"быть\", \"был\", \"него\", \"до\", \"вас\", \"нибудь\", \"опять\", \"уж\", \"вам\", \"ведь\", \"там\", \"потом\", \"себя\", \"ничего\", \"ей\", \"может\", \"они\", \"тут\", \"где\", \"есть\", \"надо\", \"ней\", \"для\", \"мы\", \"тебя\", \"их\", \"чем\", \"была\", \"сам\", \"чтоб\", \"без\", \"будто\", \"чего\", \"раз\", \"тоже\", \"себе\", \"под\", \"будет\", \"ж\", \"тогда\", \"кто\", \"этот\", \"того\", \"потому\", \"этого\", \"какой\", \"совсем\", \"ним\", \"здесь\", \"этом\", \"один\", \"почти\", \"мой\", \"тем\", \"чтобы\", \"нее\", \"сейчас\", \"были\", \"куда\", \"зачем\", \"всех\", \"никогда\", \"можно\", \"при\", \"наконец\", \"два\", \"об\", \"другой\", \"хоть\", \"после\", \"над\", \"больше\", \"тот\", \"через\", \"эти\", \"нас\", \"про\", \"всего\", \"них\", \"какая\", \"много\", \"разве\", \"три\", \"эту\", \"моя\", \"впрочем\", \"хорошо\", \"свою\", \"этой\", \"перед\", \"иногда\", \"лучше\", \"чуть\", \"том\", \"нельзя\", \"такой\", \"им\", \"более\", \"всегда\", \"конечно\", \"всю\", \"между\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['text'] = data['text'].fillna('')  # Замена значений NaN пустыми строками\n",
    "mystem = Mystem()\n",
    "\n",
    "def preprocess_text(text):\n",
    "    text = text.lower()\n",
    "    lemmas = mystem.lemmatize(text)\n",
    "    filtered_lemmas = [lemma.strip() for lemma in lemmas if lemma.strip() not in stop_words and lemma.strip() not in string.punctuation]\n",
    "    filtered_text = ' '.join(filtered_lemmas)\n",
    "    return filtered_text\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Прекрасно! Теперь у вас есть функция `preprocess_text`, которая будет очищать и нормализовать ваш текст:\n",
    "\n",
    "1. `text.lower()` приводит все буквы в тексте к нижнему регистру. Это уменьшает размер словаря и упрощает дальнейший анализ.\n",
    "\n",
    "2. `word_tokenize(text)` разбивает текст на отдельные слова, так что вы можете обработать каждое слово по отдельности.\n",
    "\n",
    "3. `[lemmatizer.lemmatize(word) for word in word_tokens if word not in stop_words and word not in string.punctuation]` это генератор списка, который проходит через каждое слово в `word_tokens`, лемматизирует его (т. е. приводит его к базовой форме) и добавляет его в список, если оно не является стоп-словом или знаком пунктуации.\n",
    "\n",
    "Обратите внимание, что вы используете `WordNetLemmatizer` из библиотеки NLTK. Этот лемматизатор основан на WordNet, большой лексической базе данных английского языка. Он может быть не очень эффективным для русского языка. Вы можете рассмотреть возможность использования других инструментов для лемматизации русского языка, таких как pymorphy2 или mystem от Яндекса."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "удаление шума"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Применить функцию preprocess_text к каждому посту\n",
    "corpus = data['text'].apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Преобразование текста в численные векторы с использованием TF-IDF\n",
    "vectorizer = TfidfVectorizer()\n",
    "X = vectorizer.fit_transform(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def remove_smileys(text):\n",
    "    # Паттерн для смайлов в виде эмодзи\n",
    "    emoji_pattern = re.compile(\"[\"\n",
    "                               u\"\\U0001F600-\\U0001F64F\"  # Смайлы эмодзи (Emoticons)\n",
    "                               u\"\\U0001F300-\\U0001F5FF\"  # Символы и пиктограммы\n",
    "                               u\"\\U0001F680-\\U0001F6FF\"  # Смайлы транспорта и картинки\n",
    "                               u\"\\U0001F1E0-\\U0001F1FF\"  # Смайлы флагов стран\n",
    "                               u\"\\U00002600-\\U000027BF\"  # Смайлы погоды\n",
    "                               u\"\\U0001F900-\\U0001F9FF\"  # Смайлы иконки\n",
    "                               u\"\\U0001F601-\\U0001F64F\"  # Смайлы эмодзи (Emoticons)\n",
    "                               u\"\\U0001F680-\\U0001F6FF\"  # Смайлы транспорта и картинки\n",
    "                               u\"\\U000024C2-\\U0001F251\"  # Смайлы иконки\n",
    "                               \"]+\", flags=re.UNICODE)\n",
    "    \n",
    "    # Удаление смайлов из текста\n",
    "    cleaned_text = emoji_pattern.sub(r'', text)\n",
    "    return cleaned_text\n",
    "\n",
    "# Применение функции remove_smileys к столбцу 'text' в датасете\n",
    "data['text'] = data['text'].apply(remove_smileys)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       post_id                                               text  likes  \\\n",
      "1     37666179   ОФИЦИАЛЬНО — Месси объявил о переходе в «Инте...   5354   \n",
      "2     37668297   Официально — Алексис Мак Аллистер — игрок «Ли...    179   \n",
      "3     37668188           Неплохие условия для Лео \\n\\n#vkfootball    587   \n",
      "4     37667981                   Что купит? «МЮ»? \\n\\n#vkfootball   1572   \n",
      "5     37667827   Почти половина АПЛ сыграет в еврокубках \\n\\nВ...    854   \n",
      "...        ...                                                ...    ...   \n",
      "1896     13759  Подготовь идеальную презентацию и питчинг прое...      5   \n",
      "1897     13758  Риск — вечный спутник бизнеса! \\n \\nКакие инве...     10   \n",
      "1898     13756  Бизнес-инкубатор ВШЭ приглашает на лекцию Кафе...      3   \n",
      "1899     13754  Бизнес-инкубатор НИУ ВШЭ представил свои прогр...      3   \n",
      "1900     13752  Что такое питч и как к нему подготовиться? Рас...     10   \n",
      "\n",
      "      reposts   views  \n",
      "1        2008  205518  \n",
      "2          27    5989  \n",
      "3          37   19536  \n",
      "4         158   41928  \n",
      "5          95   49879  \n",
      "...       ...     ...  \n",
      "1896        6     867  \n",
      "1897        7    1842  \n",
      "1898        3     809  \n",
      "1899        0     937  \n",
      "1900       17    2517  \n",
      "\n",
      "[1900 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "print (data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Определение темы поста на основе ключевых слов\n",
    "def determine_topic(text):\n",
    "    business_keywords = [\"бизнес\", \"менедж\", \"управл\", \"эконом\", \"маркет\", \"бренд\", \"предприн\", \"франш\", \"старт\", \"коммерц\", \"инвест\", \"финанс\", \"продаж\", \"стратег\", \"аналитик\", \"консульт\", \"инновац\", \"рынок\", \"проект\", \"индустри\", \"лидер\", \"партнер\", \"финансирован\", \"организац\", \"планир\", \"продукт\", \"сервис\", \"клиент\", \"потребител\", \"бюджет\", \"рентабел\", \"эффективн\", \"конкурент\", \"реклам\", \"сетев\", \"технолог\", \"интернет\", \"платформ\", \"команда\", \"персонал\", \"инновацион\", \"тренд\", \"потребност\", \"производств\", \"качеств\", \"стратегическ\", \"решени\", \"продвижен\", \"привлечен\", \"улучшен\", \"финтех\", \"цифров\", \"инвестор\", \"развит\", \"предложен\", \"бюджетирован\", \"успех\", \"консалтинг\", \"венчур\", \"индустриализац\", \"интернационализац\", \"корпоративн\", \"финансирован\", \"риски\", \"акционер\", \"современ\", \"миров\", \"сегмент\", \"контракт\", \"продуктивн\", \"лидерств\", \"выгода\", \"сбыт\", \"услуг\", \"интерес\", \"покупател\", \"капитал\", \"эксперт\", \"инициатив\", \"возможност\", \"клиентск\", \"социальн\", \"брокер\", \"портфел\", \"услов\", \"конкуренция\", \"nft\", \"денег\", \"вызов\", \"деньг\", \"миллион\"]\n",
    "    sports_keywords = [\"спорт\", \"физкультура\", \"футбол\", \"хоккей\", \"тренер\", \"инструктор\", \"соревнования\", \"турнир\", \"атлетика\", \"бег\", \"фитнес\", \"спорт\", \"физ\", \"фут\", \"хокк\", \"трен\", \"соревнован\", \"тур\", \"атлет\", \"фит\", \"плаван\", \"баскетбол\", \"волейбол\", \"теннис\", \"бокс\", \"гимнастика\", \"шахматы\", \"бейсбол\", \"гольф\", \"сноуборд\", \"лыжи\", \"биатлон\", \"катание\", \"велоспорт\", \"бодибилдинг\", \"скейтборд\", \"кроссфит\", \"пауэрлифтинг\", \"рыбалка\", \"скалолазание\", \"бокс\", \"тайский\", \"керлинг\", \"триатлон\", \"серфинг\", \"парашют\", \"дайвинг\", \"шорт-трек\", \"паркур\", \"прыжки\", \"акробатика\", \"рыцарские\", \"игры\", \"экстрим\", \"эквестрианство\", \"кайтсерфинг\", \"бодигард\", \"фехтование\", \"стрельба\", \"водное\", \"поло\", \"фристайл\", \"аэробика\", \"фигурное\", \"конькобежный\", \"спидвей\", \"санний\", \"тяжелая\", \"атлетик\", \"перетягивание\", \"каноэ\", \"рагби\", \"флорбол\", \"сквош\", \"бейджик\", \"легкая\", \"атлетика\", \"прыжки\", \"высота\", \"дзюдо\", \"каратэ\", \"баскетбол\", \"гандбол\", \"гольф\", \"стрельба\", \"спортивная\", \"гимнастика\", \"синхронное\", \"win\", \"спа\", \"цска\", \"апл\", \"рпл\", \"лео\", \"мес\", \"златан\", \"ибр\", \"лч\", \"лиг\", \"финал\", \"реал\", \"масс\", \"форм\", \"го\", \"игрок\", \"побед\", \"финале\", \"признан\", \"клуб\", \"трофей\", \"куб\", \"требл\", \"месси\", \"холанд\"]\n",
    "    music_keywords = [\"исполнител\", \"альбом\", \"концерт\", \"стил\", \"звучан\", \"текст\", \"музыкант\", \"слушател\", \"песн\", \"трек\", \"испол\", \"аль\", \"кон\", \"стил\", \"звучан\", \"текст\", \"муз\", \"слуш\", \"песн\", \"жанр\", \"мелод\", \"артист\", \"ритм\", \"аккорд\", \"дуэт\", \"сингл\", \"поп\", \"рок\", \"хип-хоп\", \"электроник\", \"джаз\", \"классик\", \"инструмент\", \"саксофон\", \"гитар\", \"пианин\", \"ударн\", \"бас\", \"вокал\", \"сол\", \"сампл\", \"бит\", \"микс\", \"саундтрек\", \"ремикс\", \"авторск\", \"пластинк\", \"композитор\", \"студ\", \"музыкальн\", \"индустри\", \"аранжировк\", \"рефрен\", \"бэк-вокал\", \"студийн\", \"музыкальн\", \"гармон\", \"сцен\", \"музыкальн\", \"продюсер\", \"клавишн\", \"синтезатор\", \"дискограф\", \"тур\", \"кавер\", \"рок-н-ролл\", \"поп-рок\", \"альтернатив\", \"рэп\", \"трэп\", \"регг\", \"ска\", \"реггетон\", \"кантр\", \"фолк\", \"инди\", \"танцевальн\", \"музык\", \"клубн\", \"панк\", \"метал\", \"блюз\", \"эмо\", \"фанк\", \"соул\", \"диско\", \"рэйв\", \"психодели\", \"хаус\", \"транс\", \"техн\", \"драм-н-бэйс\", \"дабстеп\", \"джунгл\", \"реггиджангл\", \"эмбиент\", \"ритм-энд-блюз\", \"гранж\", \"дэт-метал\", \"симфон\", \"оркестр\", \"опер\", \"концертн\", \"зал\", \"компиляц\"]\n",
    "    politics_keywords = [\"государств\", \"власт\", \"правительств\", \"парти\", \"идеолог\", \"законодательств\", \"дипломат\", \"свобод\", \"коррупц\", \"выбор\", \"кризис\", \"госу\", \"влас\", \"прав\", \"парти\", \"идеол\", \"закон\", \"дипло\", \"своб\", \"корр\", \"выбор\", \"кризис\", \"поб\", \"сво\", \"укр\", \"рос\", \"вой\", \"вс\", \"през\", \"демократ\", \"республик\", \"политик\", \"политическ\", \"политичес\", \"государствен\", \"правительствен\", \"дипломатическ\", \"дипломатичес\", \"парламент\", \"правов\", \"коррупц\", \"парламентар\", \"выборн\", \"конституц\", \"свободн\", \"демократическ\", \"политолог\", \"политологическ\", \"парламентск\", \"политическ\", \"реформ\", \"движен\", \"гражданск\", \"международн\", \"конфликт\", \"договор\", \"представител\", \"голосован\", \"оппозиц\", \"партийн\", \"правозащитн\", \"политсистем\", \"судебн\", \"правосуд\", \"законодател\", \"декларац\", \"решен\", \"международн\", \"сотрудничеств\", \"лоббирован\", \"политическ\", \"демократизац\", \"диктатур\", \"войск\", \"воен\", \"граждан\", \"конституцион\", \"региональн\", \"территориальн\", \"внутренн\", \"внешн\", \"геополитическ\", \"независим\", \"самоуправл\", \"безопасн\", \"суверен\", \"регулирован\", \"поддержк\", \"политическ\", \"экономическ\", \"социальн\", \"росс\", \"сша\", \"амер\"]\n",
    "    \n",
    "    text = text.lower()\n",
    "    words = word_tokenize(text)\n",
    "\n",
    "    for word in words:\n",
    "        for keyword in business_keywords:\n",
    "            if keyword in word:\n",
    "                return \"Бизнес\"\n",
    "        for keyword in sports_keywords:\n",
    "            if keyword in word:\n",
    "                return \"Спорт\"\n",
    "        for keyword in music_keywords:\n",
    "            if keyword in word:\n",
    "                return \"Музыка\"\n",
    "        for keyword in politics_keywords:\n",
    "            if keyword in word:\n",
    "                return \"Политика\"\n",
    "    return \"Другое\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "def determine_topic(text):\n",
    "    business_keywords = [\"бизнес\", \"менедж\", \"управл\", \"эконом\", \"маркет\", \"бренд\", \"предприн\", \"франш\", \"старт\", \"коммерц\", \"инвест\", \"финанс\", \"продаж\", \"стратег\", \"аналитик\", \"консульт\", \"инновац\", \"рынок\", \"проект\", \"индустри\", \"лидер\", \"партнер\", \"финансирован\", \"организац\", \"планир\", \"продукт\", \"сервис\", \"клиент\", \"потребител\", \"бюджет\", \"рентабел\", \"эффективн\", \"конкурент\", \"реклам\", \"сетев\", \"технолог\", \"интернет\", \"платформ\", \"команда\", \"персонал\", \"инновацион\", \"тренд\", \"потребност\", \"производств\", \"качеств\", \"стратегическ\", \"решени\", \"продвижен\", \"привлечен\", \"улучшен\", \"финтех\", \"цифров\", \"инвестор\", \"развит\", \"предложен\", \"бюджетирован\", \"успех\", \"консалтинг\", \"венчур\", \"индустриализац\", \"интернационализац\", \"корпоративн\", \"финансирован\", \"риски\", \"акционер\", \"современ\", \"миров\", \"сегмент\", \"контракт\", \"продуктивн\", \"лидерств\", \"выгода\", \"сбыт\", \"услуг\", \"интерес\", \"покупател\", \"капитал\", \"эксперт\", \"инициатив\", \"возможност\", \"клиентск\", \"социальн\", \"брокер\", \"портфел\", \"услов\", \"конкуренция\", \"nft\", \"денег\", \"вызов\", \"деньг\", \"миллион\"]\n",
    "    sports_keywords = [\"спорт\", \"физкультура\", \"футбол\", \"хоккей\", \"тренер\", \"инструктор\", \"соревнования\", \"турнир\", \"атлетика\", \"бег\", \"фитнес\", \"спорт\", \"физ\", \"фут\", \"хокк\", \"трен\", \"соревнован\", \"тур\", \"атлет\", \"фит\", \"плаван\", \"баскетбол\", \"волейбол\", \"теннис\", \"бокс\", \"гимнастика\", \"шахматы\", \"бейсбол\", \"гольф\", \"сноуборд\", \"лыжи\", \"биатлон\", \"катание\", \"велоспорт\", \"бодибилдинг\", \"скейтборд\", \"кроссфит\", \"пауэрлифтинг\", \"рыбалка\", \"скалолазание\", \"бокс\", \"тайский\", \"керлинг\", \"триатлон\", \"серфинг\", \"парашют\", \"дайвинг\", \"шорт-трек\", \"паркур\", \"прыжки\", \"акробатика\", \"рыцарские\", \"игры\", \"экстрим\", \"эквестрианство\", \"кайтсерфинг\", \"бодигард\", \"фехтование\", \"стрельба\", \"водное\", \"поло\", \"фристайл\", \"аэробика\", \"фигурное\", \"конькобежный\", \"спидвей\", \"санний\", \"тяжелая\", \"атлетик\", \"перетягивание\", \"каноэ\", \"рагби\", \"флорбол\", \"сквош\", \"бейджик\", \"легкая\", \"атлетика\", \"прыжки\", \"высота\", \"дзюдо\", \"каратэ\", \"баскетбол\", \"гандбол\", \"гольф\", \"стрельба\", \"спортивная\", \"гимнастика\", \"синхронное\", \"win\", \"спа\", \"цска\", \"апл\", \"рпл\", \"лео\", \"мес\", \"златан\", \"ибр\", \"лч\", \"лиг\", \"финал\", \"реал\", \"масс\", \"форм\", \"го\", \"игрок\", \"побед\", \"финал\", \"признан\", \"клуб\", \"трофей\", \"куб\", \"требл\", \"месси\"]\n",
    "    music_keywords = [\"исполнител\", \"альбом\", \"концерт\", \"стил\", \"звучан\", \"текст\", \"музыкант\", \"слушател\", \"песн\", \"трек\", \"испол\", \"аль\", \"кон\", \"стил\", \"звучан\", \"текст\", \"муз\", \"слуш\", \"песн\", \"жанр\", \"мелод\", \"артист\", \"ритм\", \"аккорд\", \"дуэт\", \"сингл\", \"поп\", \"рок\", \"хип-хоп\", \"электроник\", \"джаз\", \"классик\", \"инструмент\", \"саксофон\", \"гитар\", \"пианин\", \"ударн\", \"бас\", \"вокал\", \"сол\", \"сампл\", \"бит\", \"микс\", \"саундтрек\", \"ремикс\", \"авторск\", \"пластинк\", \"композитор\", \"студ\", \"музыкальн\", \"индустри\", \"аранжировк\", \"рефрен\", \"бэк-вокал\", \"студийн\", \"музыкальн\", \"гармон\", \"сцен\", \"музыкальн\", \"продюсер\", \"клавишн\", \"синтезатор\", \"дискограф\", \"тур\", \"кавер\", \"рок-н-ролл\", \"поп-рок\", \"альтернатив\", \"рэп\", \"трэп\", \"регг\", \"ска\", \"реггетон\", \"кантр\", \"фолк\", \"инди\", \"танцевальн\", \"музык\", \"клубн\", \"панк\", \"метал\", \"блюз\", \"эмо\", \"фанк\", \"соул\", \"диско\", \"рэйв\", \"психодели\", \"хаус\", \"транс\", \"техн\", \"драм-н-бэйс\", \"дабстеп\", \"джунгл\", \"реггиджангл\", \"эмбиент\", \"ритм-энд-блюз\", \"гранж\", \"дэт-метал\", \"симфон\", \"оркестр\", \"опер\", \"концертн\", \"зал\", \"компиляц\"]\n",
    "    politics_keywords = [\"государств\", \"власт\", \"правительств\", \"парти\", \"идеолог\", \"законодательств\", \"дипломат\", \"свобод\", \"коррупц\", \"выбор\", \"кризис\", \"госу\", \"влас\", \"прав\", \"парти\", \"идеол\", \"закон\", \"дипло\", \"своб\", \"корр\", \"выбор\", \"кризис\", \"поб\", \"сво\", \"укр\", \"рос\", \"вой\", \"вс\", \"през\", \"демократ\", \"республик\", \"политик\", \"политическ\", \"политичес\", \"государствен\", \"правительствен\", \"дипломатическ\", \"дипломатичес\", \"парламент\", \"правов\", \"коррупц\", \"парламентар\", \"выборн\", \"конституц\", \"свободн\", \"демократическ\", \"политолог\", \"политологическ\", \"парламентск\", \"политическ\", \"реформ\", \"движен\", \"гражданск\", \"международн\", \"конфликт\", \"договор\", \"представител\", \"голосован\", \"оппозиц\", \"партийн\", \"правозащитн\", \"политсистем\", \"судебн\", \"правосуд\", \"законодател\", \"декларац\", \"решен\", \"международн\", \"сотрудничеств\", \"лоббирован\", \"политическ\", \"демократизац\", \"диктатур\", \"войск\", \"воен\", \"граждан\", \"конституцион\", \"региональн\", \"территориальн\", \"внутренн\", \"внешн\", \"геополитическ\", \"независим\", \"самоуправл\", \"безопасн\", \"суверен\", \"регулирован\", \"поддержк\", \"политическ\", \"экономическ\", \"социальн\", \"росс\", \"сша\", \"амер\"]\n",
    "\n",
    "    text = text.lower()\n",
    "    words = word_tokenize(text)\n",
    "\n",
    "    category_count = {\n",
    "        \"Бизнес\": 0,\n",
    "        \"Спорт\": 0,\n",
    "        \"Музыка\": 0,\n",
    "        \"Политика\": 0,\n",
    "        \"Другое\": 0\n",
    "    }\n",
    "\n",
    "    for word in words:\n",
    "        if word in business_keywords:\n",
    "            category_count[\"Бизнес\"] += 1\n",
    "        if word in sports_keywords:\n",
    "            category_count[\"Спорт\"] += 1\n",
    "        if word in music_keywords:\n",
    "            category_count[\"Музыка\"] += 1\n",
    "        if word in politics_keywords:\n",
    "            category_count[\"Политика\"] += 1\n",
    "    if max(category_count.values()) == 0:\n",
    "        return \"Другое\"\n",
    "\n",
    "    max_count = max(category_count.values())\n",
    "    max_topics = [topic for topic, count in category_count.items() if count == max_count]\n",
    "\n",
    "    return max_topics[0]  # Возвращаем первую тему с наибольшим количеством совпадений\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "def determine_topic(text):\n",
    "    business_keywords = [\"бизнес\", \"менедж\", \"управл\", \"эконом\", \"маркет\", \"бренд\", \"предприн\", \"франш\", \"старт\", \"коммерц\", \"инвест\", \"финанс\", \"продаж\", \"стратег\", \"аналитик\", \"консульт\", \"инновац\", \"рынок\", \"проект\", \"индустри\", \"лидер\", \"партнер\", \"финансирован\", \"организац\", \"планир\", \"продукт\", \"сервис\", \"клиент\", \"потребител\", \"бюджет\", \"рентабел\", \"эффективн\", \"конкурент\", \"реклам\", \"сетев\", \"технолог\", \"интернет\", \"платформ\", \"команда\", \"персонал\", \"инновацион\", \"тренд\", \"потребност\", \"производств\", \"качеств\", \"стратегическ\", \"решени\", \"продвижен\", \"привлечен\", \"улучшен\", \"финтех\", \"цифров\", \"инвестор\", \"развит\", \"предложен\", \"бюджетирован\", \"успех\", \"консалтинг\", \"венчур\", \"индустриализац\", \"интернационализац\", \"корпоративн\", \"финансирован\", \"риски\", \"акционер\", \"современ\", \"миров\", \"сегмент\", \"контракт\", \"продуктивн\", \"лидерств\", \"выгода\", \"сбыт\", \"услуг\", \"интерес\", \"покупател\", \"капитал\", \"эксперт\", \"инициатив\", \"возможност\", \"клиентск\", \"социальн\", \"брокер\", \"портфел\", \"услов\", \"конкуренция\", \"nft\", \"денег\", \"вызов\", \"деньг\", \"миллион\"]\n",
    "    sports_keywords = [\"спорт\", \"физкультура\", \"футбол\", \"хоккей\", \"тренер\", \"инструктор\", \"соревнования\", \"турнир\", \"атлетика\", \"бег\", \"фитнес\", \"спорт\", \"физ\", \"фут\", \"хокк\", \"трен\", \"соревнован\", \"тур\", \"атлет\", \"фит\", \"плаван\", \"баскетбол\", \"волейбол\", \"теннис\", \"бокс\", \"гимнастика\", \"шахматы\", \"бейсбол\", \"гольф\", \"сноуборд\", \"лыжи\", \"биатлон\", \"катание\", \"велоспорт\", \"бодибилдинг\", \"скейтборд\", \"кроссфит\", \"пауэрлифтинг\", \"рыбалка\", \"скалолазание\", \"бокс\", \"тайский\", \"керлинг\", \"триатлон\", \"серфинг\", \"парашют\", \"дайвинг\", \"шорт-трек\", \"паркур\", \"прыжки\", \"акробатика\", \"рыцарские\", \"игры\", \"экстрим\", \"эквестрианство\", \"кайтсерфинг\", \"бодигард\", \"фехтование\", \"стрельба\", \"водное\", \"поло\", \"фристайл\", \"аэробика\", \"фигурное\", \"конькобежный\", \"спидвей\", \"санний\", \"тяжелая\", \"атлетик\", \"перетягивание\", \"каноэ\", \"рагби\", \"флорбол\", \"сквош\", \"бейджик\", \"легкая\", \"атлетика\", \"прыжки\", \"высота\", \"дзюдо\", \"каратэ\", \"баскетбол\", \"гандбол\", \"гольф\", \"стрельба\", \"спортивная\", \"гимнастика\", \"синхронное\", \"win\", \"спа\", \"цска\", \"апл\", \"рпл\", \"лео\", \"мес\", \"златан\", \"ибр\", \"лч\", \"лиг\", \"финал\", \"реал\", \"масс\", \"форм\", \"го\", \"игрок\", \"побед\", \"финал\", \"признан\", \"клуб\", \"трофей\", \"куб\", \"требл\", \"месси\"]\n",
    "    music_keywords = [\"исполнител\", \"альбом\", \"концерт\", \"стил\", \"звучан\", \"текст\", \"музыкант\", \"слушател\", \"песн\", \"трек\", \"испол\", \"аль\", \"кон\", \"стил\", \"звучан\", \"текст\", \"муз\", \"слуш\", \"песн\", \"жанр\", \"мелод\", \"артист\", \"ритм\", \"аккорд\", \"дуэт\", \"сингл\", \"поп\", \"рок\", \"хип-хоп\", \"электроник\", \"джаз\", \"классик\", \"инструмент\", \"саксофон\", \"гитар\", \"пианин\", \"ударн\", \"бас\", \"вокал\", \"сол\", \"сампл\", \"бит\", \"микс\", \"саундтрек\", \"ремикс\", \"авторск\", \"пластинк\", \"композитор\", \"студ\", \"музыкальн\", \"индустри\", \"аранжировк\", \"рефрен\", \"бэк-вокал\", \"студийн\", \"музыкальн\", \"гармон\", \"сцен\", \"музыкальн\", \"продюсер\", \"клавишн\", \"синтезатор\", \"дискограф\", \"тур\", \"кавер\", \"рок-н-ролл\", \"поп-рок\", \"альтернатив\", \"рэп\", \"трэп\", \"регг\", \"ска\", \"реггетон\", \"кантр\", \"фолк\", \"инди\", \"танцевальн\", \"музык\", \"клубн\", \"панк\", \"метал\", \"блюз\", \"эмо\", \"фанк\", \"соул\", \"диско\", \"рэйв\", \"психодели\", \"хаус\", \"транс\", \"техн\", \"драм-н-бэйс\", \"дабстеп\", \"джунгл\", \"реггиджангл\", \"эмбиент\", \"ритм-энд-блюз\", \"гранж\", \"дэт-метал\", \"симфон\", \"оркестр\", \"опер\", \"концертн\", \"зал\", \"компиляц\"]\n",
    "    politics_keywords = [\"государств\", \"власт\", \"правительств\", \"парти\", \"идеолог\", \"законодательств\", \"дипломат\", \"свобод\", \"коррупц\", \"выбор\", \"кризис\", \"госу\", \"влас\", \"прав\", \"парти\", \"идеол\", \"закон\", \"дипло\", \"своб\", \"корр\", \"выбор\", \"кризис\", \"поб\", \"сво\", \"укр\", \"рос\", \"вой\", \"вс\", \"през\", \"демократ\", \"республик\", \"политик\", \"политическ\", \"политичес\", \"государствен\", \"правительствен\", \"дипломатическ\", \"дипломатичес\", \"парламент\", \"правов\", \"коррупц\", \"парламентар\", \"выборн\", \"конституц\", \"свободн\", \"демократическ\", \"политолог\", \"политологическ\", \"парламентск\", \"политическ\", \"реформ\", \"движен\", \"гражданск\", \"международн\", \"конфликт\", \"договор\", \"представител\", \"голосован\", \"оппозиц\", \"партийн\", \"правозащитн\", \"политсистем\", \"судебн\", \"правосуд\", \"законодател\", \"декларац\", \"решен\", \"международн\", \"сотрудничеств\", \"лоббирован\", \"политическ\", \"демократизац\", \"диктатур\", \"войск\", \"воен\", \"граждан\", \"конституцион\", \"региональн\", \"территориальн\", \"внутренн\", \"внешн\", \"геополитическ\", \"независим\", \"самоуправл\", \"безопасн\", \"суверен\", \"регулирован\", \"поддержк\", \"политическ\", \"экономическ\", \"социальн\", \"росс\", \"сша\", \"амер\"]\n",
    "\n",
    "    text = text.lower()\n",
    "    words = word_tokenize(text)\n",
    "\n",
    "    # Проверяем наличие ключевых слов в тексте\n",
    "    for word in words:\n",
    "        for keyword in business_keywords:\n",
    "            if keyword in word:\n",
    "                return \"Бизнес\"\n",
    "        for keyword in sports_keywords:\n",
    "            if keyword in word:\n",
    "                return \"Спорт\"\n",
    "        for keyword in music_keywords:\n",
    "            if keyword in word:\n",
    "                return \"Музыка\"\n",
    "        for keyword in politics_keywords:\n",
    "            if keyword in word:\n",
    "                return \"Политика\"\n",
    "    \n",
    "    # Если не было совпадений, используем подсчет количества совпадений\n",
    "    category_count = {\n",
    "        \"Бизнес\": 0,\n",
    "        \"Спорт\": 0,\n",
    "        \"Музыка\": 0,\n",
    "        \"Политика\": 0,\n",
    "        \"Другое\": 0\n",
    "    }\n",
    "\n",
    "    for word in words:\n",
    "        if word in business_keywords:\n",
    "            category_count[\"Бизнес\"] += 1\n",
    "        if word in sports_keywords:\n",
    "            category_count[\"Спорт\"] += 1\n",
    "        if word in music_keywords:\n",
    "            category_count[\"Музыка\"] += 1\n",
    "        if word in politics_keywords:\n",
    "            category_count[\"Политика\"] += 1\n",
    "    \n",
    "    max_count = max(category_count.values())\n",
    "    \n",
    "    if max_count > 0:\n",
    "        max_topics = [topic for topic, count in category_count.items() if count == max_count]\n",
    "        return max_topics[0]  # Возвращаем первую тему с наибольшим количеством совпадений\n",
    "    \n",
    "    return \"Другое\"  # Если нет совпадений, возвращаем \"Другое\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Применить функцию determine_topic к каждому посту\n",
    "data['topic'] = data['text'].apply(determine_topic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                   text   topic\n",
      "1      ОФИЦИАЛЬНО — Месси объявил о переходе в «Инте...  Музыка\n",
      "2      Официально — Алексис Мак Аллистер — игрок «Ли...  Музыка\n",
      "3              Неплохие условия для Лео \\n\\n#vkfootball  Бизнес\n",
      "4                      Что купит? «МЮ»? \\n\\n#vkfootball  Другое\n",
      "5      Почти половина АПЛ сыграет в еврокубках \\n\\nВ...   Спорт\n",
      "...                                                 ...     ...\n",
      "1896  Подготовь идеальную презентацию и питчинг прое...   Спорт\n",
      "1897  Риск — вечный спутник бизнеса! \\n \\nКакие инве...  Бизнес\n",
      "1898  Бизнес-инкубатор ВШЭ приглашает на лекцию Кафе...  Бизнес\n",
      "1899  Бизнес-инкубатор НИУ ВШЭ представил свои прогр...  Бизнес\n",
      "1900  Что такое питч и как к нему подготовиться? Рас...   Спорт\n",
      "\n",
      "[1900 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# Вывести результаты с определенными темами\n",
    "print(data[['text', 'topic']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Данные сохранены в файл filtered_data.csv\n"
     ]
    }
   ],
   "source": [
    "def save_table_data_to_csv(data):\n",
    "    # Выбор только указанных столбцов\n",
    "    filtered_data = data[['text', 'topic']]\n",
    "\n",
    "    # Сохранение данных в новый файл CSV\n",
    "    filtered_data.to_csv('filtered_data.csv', index=False)\n",
    "\n",
    "    print(\"Данные сохранены в файл filtered_data.csv\")\n",
    "\n",
    "# Вызов функции для сохранения данных из объекта DataFrame в файл CSV\n",
    "save_table_data_to_csv(data)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В данном коде используется модель LSTM (Long Short-Term Memory) для классификации текстовых данных.\n",
    "\n",
    "Этапы работы с моделью в данном коде:\n",
    "\n",
    "1. Объединение отсутствующих категорий: Отсутствующие категории в тренировочном и тестовом наборах данных объединяются в категорию \"Другое\" путем замены соответствующих значений в массивах `X_train`, `y_train`, `X_test` и `y_test`.\n",
    "\n",
    "2. Кодирование меток классов: Метки классов `y_train` и `y_test` кодируются с помощью объекта `LabelEncoder` для преобразования текстовых меток в числовые значения.\n",
    "\n",
    "3. Преобразование текста в числовые последовательности: Текстовые данные из `X_train` и `X_test` преобразуются в числовые последовательности с помощью объекта `Tokenizer`. Каждое слово заменяется на соответствующий индекс, полученный из словаря слов `tokenizer.word_index`.\n",
    "\n",
    "4. Приведение последовательностей к фиксированной длине: Последовательности числовых значений приводятся к фиксированной длине `max_sequence_length` с помощью функции `pad_sequences`. Если последовательность короче, она дополняется нулями, а если длиннее, то обрезается.\n",
    "\n",
    "5. Создание модели LSTM: Создается объект модели `Sequential`, к которому последовательно добавляются слои. В данном случае добавляются слои `Embedding`, `LSTM` и `Dense`. Слой `Embedding` преобразует индексы слов в векторные представления, слой `LSTM` выполняет обработку последовательностей, а слой `Dense` представляет выходной слой с функцией активации `softmax` для классификации.\n",
    "\n",
    "6. Компиляция модели: Модель компилируется с функцией потерь `sparse_categorical_crossentropy` и оптимизатором `adam`.\n",
    "\n",
    "7. Обучение модели: Модель обучается на тренировочных данных `X_train_padded` и `y_train_encoded` с заданным количеством эпох и размером пакета. Валидационные данные `X_test_padded` и `y_test_encoded` используются для проверки модели на каждой эпохе.\n",
    "\n",
    "8. Оценка модели: Модель оценивается на тестовых данных с использованием функции `evaluate()`, и выводится точность (`accuracy`) модели."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "48/48 [==============================] - 4s 75ms/step - loss: 1.4818 - accuracy: 0.3632 - val_loss: 1.3776 - val_accuracy: 0.4263\n",
      "Epoch 2/10\n",
      "48/48 [==============================] - 3s 70ms/step - loss: 1.2131 - accuracy: 0.4717 - val_loss: 1.3007 - val_accuracy: 0.4395\n",
      "Epoch 3/10\n",
      "48/48 [==============================] - 4s 78ms/step - loss: 0.7343 - accuracy: 0.7664 - val_loss: 1.3710 - val_accuracy: 0.4605\n",
      "Epoch 4/10\n",
      "48/48 [==============================] - 4s 76ms/step - loss: 0.2618 - accuracy: 0.9243 - val_loss: 1.5007 - val_accuracy: 0.4553\n",
      "Epoch 5/10\n",
      "48/48 [==============================] - 4s 75ms/step - loss: 0.0719 - accuracy: 0.9868 - val_loss: 1.7711 - val_accuracy: 0.4684\n",
      "Epoch 6/10\n",
      "48/48 [==============================] - 4s 74ms/step - loss: 0.0289 - accuracy: 0.9954 - val_loss: 1.9845 - val_accuracy: 0.4816\n",
      "Epoch 7/10\n",
      "48/48 [==============================] - 4s 74ms/step - loss: 0.0156 - accuracy: 0.9987 - val_loss: 2.3330 - val_accuracy: 0.4526\n",
      "Epoch 8/10\n",
      "48/48 [==============================] - 3s 73ms/step - loss: 0.0105 - accuracy: 0.9980 - val_loss: 2.3514 - val_accuracy: 0.4579\n",
      "Epoch 9/10\n",
      "48/48 [==============================] - 3s 68ms/step - loss: 0.0072 - accuracy: 1.0000 - val_loss: 2.4953 - val_accuracy: 0.4816\n",
      "Epoch 10/10\n",
      "48/48 [==============================] - 3s 69ms/step - loss: 0.0050 - accuracy: 0.9993 - val_loss: 2.5289 - val_accuracy: 0.4658\n",
      "12/12 [==============================] - 0s 19ms/step - loss: 2.5289 - accuracy: 0.4658\n",
      "Accuracy: 0.46578946709632874\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils import resample\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, LSTM, Dense\n",
    "import tensorflow as tf\n",
    "\n",
    "# Разделение датасета на обучающую и тестовую выборки\n",
    "X_train, X_test, y_train, y_test = train_test_split(data['text'], data['topic'], test_size=0.2, random_state=42)\n",
    "\n",
    "all_categories = ['Бизнес', 'Спорт', 'Музыка', 'Политика']\n",
    "\n",
    "# Объединение всех отсутствующих категорий в \"Другое\"\n",
    "missing_categories_train = set(all_categories) - set(y_train.unique())\n",
    "if missing_categories_train:\n",
    "    y_train = y_train.apply(lambda x: 'Другое' if x in missing_categories_train else x)\n",
    "\n",
    "missing_categories_test = set(all_categories) - set(y_test.unique())\n",
    "if missing_categories_test:\n",
    "    y_test = y_test.apply(lambda x: 'Другое' if x in missing_categories_test else x)\n",
    "\n",
    "# Кодирование меток классов\n",
    "label_encoder = LabelEncoder()\n",
    "y_train_encoded = label_encoder.fit_transform(y_train)\n",
    "y_test_encoded = label_encoder.transform(y_test)\n",
    "\n",
    "# Преобразование текста в числовые последовательности\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "X_train_sequences = tokenizer.texts_to_sequences(X_train)\n",
    "X_test_sequences = tokenizer.texts_to_sequences(X_test)\n",
    "\n",
    "# Приведение последовательностей к фиксированной длине\n",
    "max_sequence_length = 100  # Максимальная длина последовательности\n",
    "X_train_padded = pad_sequences(X_train_sequences, maxlen=max_sequence_length)\n",
    "X_test_padded = pad_sequences(X_test_sequences, maxlen=max_sequence_length)\n",
    "\n",
    "# Создание модели LSTM\n",
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=len(tokenizer.word_index) + 1, output_dim=100, input_length=max_sequence_length))\n",
    "model.add(LSTM(units=128))\n",
    "model.add(Dense(units=len(label_encoder.classes_), activation='softmax'))\n",
    "\n",
    "# Компиляция модели\n",
    "#model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "#замена\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer=tf.keras.optimizers.legacy.Adam(), metrics=['accuracy'])\n",
    "\n",
    "\n",
    "# Обучение модели\n",
    "model.fit(X_train_padded, y_train_encoded, epochs=10, batch_size=32, validation_data=(X_test_padded, y_test_encoded))\n",
    "\n",
    "# Оценка модели\n",
    "_, accuracy = model.evaluate(X_test_padded, y_test_encoded)\n",
    "print('Accuracy:', accuracy)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "тестирование "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60/60 [==============================] - 1s 21ms/step\n",
      "['Музыка' 'Музыка' 'Бизнес' ... 'Бизнес' 'Бизнес' 'Спорт']\n"
     ]
    }
   ],
   "source": [
    "#это тест на том же самом \n",
    "import numpy as np\n",
    "# Загрузка новых данных для тестирования\n",
    "new_data = pd.read_csv('/Users/kirillshevchenko/Desktop/8сем/оирс/3 дз/hw3/table_data.csv')\n",
    "\n",
    "new_data['text'] = new_data['text'].fillna('')\n",
    "\n",
    "# Предобработка новых данных\n",
    "new_X = new_data['text']\n",
    "new_X_sequences = tokenizer.texts_to_sequences(new_X)\n",
    "new_X_padded = pad_sequences(new_X_sequences, maxlen=max_sequence_length)\n",
    "\n",
    "# Прогнозирование классов для новых данных\n",
    "predictions = model.predict(new_X_padded)\n",
    "predicted_labels = label_encoder.inverse_transform(np.argmax(predictions, axis=1))\n",
    "\n",
    "# Вывод предсказанных меток классов\n",
    "print(predicted_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 0s 20ms/step - loss: 2.5289 - accuracy: 0.4658\n",
      "Test Accuracy: 0.46578946709632874\n",
      "12/12 [==============================] - 0s 24ms/step\n",
      "Test Predictions: ['Бизнес' 'Политика' 'Политика' 'Бизнес' 'Спорт' 'Спорт' 'Другое' 'Музыка'\n",
      " 'Музыка' 'Политика' 'Бизнес' 'Музыка' 'Музыка' 'Музыка' 'Спорт' 'Спорт'\n",
      " 'Спорт' 'Музыка' 'Другое' 'Спорт' 'Другое' 'Спорт' 'Политика' 'Музыка'\n",
      " 'Политика' 'Другое' 'Политика' 'Политика' 'Другое' 'Спорт' 'Политика'\n",
      " 'Бизнес' 'Политика' 'Спорт' 'Бизнес' 'Спорт' 'Музыка' 'Политика'\n",
      " 'Политика' 'Другое' 'Спорт' 'Политика' 'Музыка' 'Музыка' 'Музыка'\n",
      " 'Музыка' 'Спорт' 'Спорт' 'Спорт' 'Политика' 'Музыка' 'Музыка' 'Спорт'\n",
      " 'Музыка' 'Политика' 'Музыка' 'Другое' 'Спорт' 'Политика' 'Спорт' 'Спорт'\n",
      " 'Спорт' 'Музыка' 'Политика' 'Политика' 'Политика' 'Бизнес' 'Музыка'\n",
      " 'Спорт' 'Бизнес' 'Политика' 'Бизнес' 'Другое' 'Спорт' 'Спорт' 'Спорт'\n",
      " 'Спорт' 'Спорт' 'Спорт' 'Спорт' 'Политика' 'Музыка' 'Другое' 'Политика'\n",
      " 'Спорт' 'Политика' 'Музыка' 'Бизнес' 'Другое' 'Другое' 'Спорт' 'Спорт'\n",
      " 'Бизнес' 'Музыка' 'Другое' 'Политика' 'Политика' 'Спорт' 'Спорт' 'Другое'\n",
      " 'Другое' 'Спорт' 'Музыка' 'Спорт' 'Спорт' 'Музыка' 'Музыка' 'Спорт'\n",
      " 'Музыка' 'Музыка' 'Спорт' 'Спорт' 'Бизнес' 'Политика' 'Музыка' 'Спорт'\n",
      " 'Политика' 'Музыка' 'Музыка' 'Спорт' 'Спорт' 'Спорт' 'Музыка' 'Политика'\n",
      " 'Музыка' 'Спорт' 'Политика' 'Бизнес' 'Спорт' 'Музыка' 'Спорт' 'Музыка'\n",
      " 'Музыка' 'Спорт' 'Спорт' 'Музыка' 'Музыка' 'Спорт' 'Другое' 'Другое'\n",
      " 'Политика' 'Бизнес' 'Другое' 'Другое' 'Политика' 'Политика' 'Музыка'\n",
      " 'Спорт' 'Музыка' 'Спорт' 'Музыка' 'Другое' 'Политика' 'Спорт' 'Спорт'\n",
      " 'Политика' 'Музыка' 'Спорт' 'Музыка' 'Политика' 'Другое' 'Музыка'\n",
      " 'Музыка' 'Другое' 'Музыка' 'Другое' 'Музыка' 'Музыка' 'Другое' 'Политика'\n",
      " 'Спорт' 'Спорт' 'Музыка' 'Музыка' 'Спорт' 'Спорт' 'Политика' 'Бизнес'\n",
      " 'Музыка' 'Спорт' 'Спорт' 'Музыка' 'Музыка' 'Другое' 'Музыка' 'Политика'\n",
      " 'Спорт' 'Политика' 'Другое' 'Спорт' 'Музыка' 'Спорт' 'Политика' 'Музыка'\n",
      " 'Музыка' 'Спорт' 'Спорт' 'Спорт' 'Музыка' 'Политика' 'Спорт' 'Спорт'\n",
      " 'Спорт' 'Музыка' 'Спорт' 'Другое' 'Другое' 'Другое' 'Музыка' 'Спорт'\n",
      " 'Музыка' 'Спорт' 'Спорт' 'Музыка' 'Политика' 'Бизнес' 'Музыка' 'Музыка'\n",
      " 'Политика' 'Политика' 'Политика' 'Музыка' 'Другое' 'Бизнес' 'Политика'\n",
      " 'Спорт' 'Спорт' 'Музыка' 'Музыка' 'Спорт' 'Другое' 'Другое' 'Музыка'\n",
      " 'Спорт' 'Музыка' 'Другое' 'Другое' 'Бизнес' 'Политика' 'Бизнес'\n",
      " 'Политика' 'Бизнес' 'Другое' 'Политика' 'Политика' 'Спорт' 'Музыка'\n",
      " 'Другое' 'Спорт' 'Музыка' 'Другое' 'Спорт' 'Другое' 'Бизнес' 'Политика'\n",
      " 'Другое' 'Спорт' 'Политика' 'Другое' 'Спорт' 'Музыка' 'Музыка' 'Спорт'\n",
      " 'Музыка' 'Спорт' 'Спорт' 'Политика' 'Спорт' 'Спорт' 'Спорт' 'Политика'\n",
      " 'Другое' 'Бизнес' 'Спорт' 'Бизнес' 'Политика' 'Политика' 'Спорт' 'Бизнес'\n",
      " 'Музыка' 'Политика' 'Музыка' 'Спорт' 'Музыка' 'Музыка' 'Спорт' 'Другое'\n",
      " 'Политика' 'Музыка' 'Музыка' 'Музыка' 'Спорт' 'Политика' 'Спорт' 'Другое'\n",
      " 'Бизнес' 'Музыка' 'Другое' 'Музыка' 'Бизнес' 'Музыка' 'Другое' 'Спорт'\n",
      " 'Спорт' 'Политика' 'Музыка' 'Спорт' 'Спорт' 'Спорт' 'Спорт' 'Другое'\n",
      " 'Спорт' 'Музыка' 'Политика' 'Другое' 'Спорт' 'Политика' 'Спорт' 'Спорт'\n",
      " 'Музыка' 'Политика' 'Спорт' 'Политика' 'Политика' 'Музыка' 'Спорт'\n",
      " 'Спорт' 'Спорт' 'Спорт' 'Спорт' 'Спорт' 'Бизнес' 'Музыка' 'Спорт' 'Спорт'\n",
      " 'Политика' 'Музыка' 'Другое' 'Музыка' 'Спорт' 'Другое' 'Музыка' 'Музыка'\n",
      " 'Спорт' 'Спорт' 'Музыка' 'Спорт' 'Спорт' 'Другое' 'Музыка' 'Другое'\n",
      " 'Другое' 'Музыка' 'Другое' 'Спорт' 'Политика' 'Политика' 'Спорт' 'Спорт'\n",
      " 'Музыка' 'Спорт' 'Спорт' 'Музыка' 'Другое' 'Спорт' 'Спорт' 'Спорт'\n",
      " 'Музыка' 'Спорт' 'Музыка' 'Музыка' 'Политика' 'Музыка' 'Другое'\n",
      " 'Политика' 'Спорт' 'Политика' 'Спорт' 'Музыка' 'Музыка']\n"
     ]
    }
   ],
   "source": [
    "# Оценка модели на тестовом наборе\n",
    "_, test_accuracy = model.evaluate(X_test_padded, y_test_encoded)\n",
    "print('Test Accuracy:', test_accuracy)\n",
    "\n",
    "# Прогнозирование классов для тестового набора\n",
    "test_predictions = model.predict(X_test_padded)\n",
    "test_predicted_labels = label_encoder.inverse_transform(np.argmax(test_predictions, axis=1))\n",
    "\n",
    "# Вывод предсказанных меток классов на тестовом наборе\n",
    "print('Test Predictions:', test_predicted_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: path_to_my_model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: path_to_my_model/assets\n"
     ]
    }
   ],
   "source": [
    "model.save('path_to_my_model', save_format='tf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Сохранение токенизатора\n",
    "with open('tokenizer.pickle', 'wb') as handle:\n",
    "    pickle.dump(tokenizer, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Сохранение LabelEncoder\n",
    "with open('label_encoder.pickle', 'wb') as le_file:\n",
    "    pickle.dump(label_encoder, le_file)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
